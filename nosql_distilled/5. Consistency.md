### Update Consistency
This issue is called a write-write conflict: two people updating the same data item at the same time.

When the writes reach the server, the server will serialize them—decide to apply one, then the other. 
Let’s assume it uses alphabetical order and picks Martin’s update first, then Pramod’s. Without any concurrency control,
Martin’s update would be applied and immediately overwritten by Pramod’s. In this case Martin’s is a lost update. Here 
the lost update is not a big problem, but often it is. We see this as a failure of consistency because Pramod’s update 
was based on the state before Martin’s update, yet was applied after it.

A common optimistic approach is a conditional update where any client that does an update tests the value just before 
updating it to see if it’s changed since his last read. In this case, Martin’s update would succeed but Pramod’s would 
fail. The error would let Pramod know that he should look at the value again and decide whether to attempt a further
update.

Both the pessimistic and optimistic approaches that we’ve just described rely on a consistent serialization of the updates.
With a single server, this is obvious—it has to choose one, then the other. But if there’s more than one server, such as
with peer-to-peer replication, then two nodes might apply the updates in a different order, resulting in a different 
value for the telephone number on each peer. Often, when people talk about concurrency in distributed systems, they talk
about sequential consistency—ensuring that all nodes apply operations in the same order.

There is another optimistic way to handle a write-write conflict—save both updates and record that they are in conflict.
This approach is familiar to many programmers from version control systems, particularly distributed version control 
systems that by their nature will often have conflicting commits. The next step again follows from version control: You 
have to merge the two updates somehow. Maybe you show both values to the user and ask them to sort it out—this is what 
happens if you update the same contact on your phone and your computer. Alternatively, the computer may be able to perform
the merge itself; if it was a phone formatting issue, it may be able to realize that and apply the new number with the 
standard format. Any automated merge of write-write conflicts is highly domain-specific and needs to be programmed for 
each particular case.

Often, when people first encounter these issues, their reaction is to prefer pessimistic concurrency because they are 
determined to avoid conflicts. While in some cases this is the right answer, there is always a tradeoff. Concurrent 
programming involves a fundamental tradeoff between safety (avoiding errors such as update conflicts) and liveness 
(responding quickly to clients). Pessimistic approaches often severely degrade the responsiveness of a system to the 
degree that it becomes unfit for its purpose. This problem is made worse by the danger of errors—pessimistic concurrency
often leads to deadlocks, which are hard to prevent and debug.

Replication makes it much more likely to run into write-write conflicts. If different nodes have different copies of some
data which can be independently updated, then you’ll get conflicts unless you take specific measures to avoid them. 
Using a single node as the target for all writes for some data makes it much easier to maintain update consistency.
Of the distribution models we discussed earlier, all but peer-to-peer replication do this.

###  Read Consistency

Having a data store that maintains update consistency is one thing, but it doesn’t guarantee that readers of that data 
store will always get consistent responses to their requests. Let’s imagine we have an order with line items and a shipping
charge. The shipping charge is calculated based on the line items in the order. If we add a line item, we thus also need 
to recalculate and update the shipping charge. In a relational database, the shipping charge and line items will be in 
separate tables. The danger of inconsistency is that Martin adds a line item to his order, Pramod then reads the line 
items and shipping charge, and then Martin updates the shipping charge. This is an inconsistent read or read-write conflict:
In Figure 5.1 Pramod has done a read in the middle of Martin’s write.

We refer to this type of consistency as logical consistency: ensuring that different data items make sense together. To 
avoid a logically inconsistent read-write conflict, relational databases support the notion of transactions. Providing
Martin wraps his two writes in a transaction, the system guarantees that Pramod will either read both data items before
the update or both after the update.

A common claim we hear is that NoSQL databases don’t support transactions and thus can’t be consistent. Such claim is 
mostly wrong because it glosses over lots of important details. Our first clarification is that any statement about lack
of transactions usually only applies to some NoSQL databases, in particular the aggregate-oriented ones. In contrast, 
graph databases tend to support ACID transactions just the same as relational databases.

Secondly, aggregate-oriented databases do support atomic updates, but only within a single aggregate. This means that you
will have logical consistency within an aggregate but not between aggregates. So in the example, you could avoid running
into that inconsistency if the order, the delivery charge, and the line items are all part of a single order aggregate.

Of course not all data can be put in the same aggregate, so any update that affects multiple aggregates leaves open a time
when clients could perform an inconsistent read. The length of time an inconsistency is present is called the inconsistency
window. A NoSQL system may have a quite short inconsistency window: As one data point, Amazon’s documentation says that
the inconsistency window for its SimpleDB service is usually less than a second.

This example of a logically inconsistent read is the classic example that you’ll see in any book that touches database
programming. Once you introduce replication, however, you get a whole new kind of inconsistency. Let’s imagine there’s 
one last hotel room for a desirable event. The hotel reservation system runs on many nodes. Martin and Cindy are a couple
considering this room, but they are discussing this on the phone because Martin is in London and Cindy is in Boston. 
Meanwhile Pramod, who is in Mumbai, goes and books that last room. That updates the replicated room availability, but 
the update gets to Boston quicker than it gets to London. When Martin and Cindy fire up their browsers to see if the 
room is available, Cindy sees it booked and Martin sees it free. This is another inconsistent read—but it’s a breach of
a different form of consistency we call replication consistency: ensuring that the same data item has the same value when
read from different replicas

Eventually, of course, the updates will propagate fully, and Martin will see the room is fully booked. Therefore this 
situation is generally referred to as eventually consistent, meaning that at any time nodes may have replication 
inconsistencies but, if there are no further updates, eventually all nodes will be updated to the same value. Data that 
is out of date is generally referred to as stale

Therein lies a danger: You may post a message using one node, then refresh your browser, but the refresh goes to a 
different node which hasn’t received your post yet—and it looks like your post was lost.

There are a couple of techniques to provide session consistency. A common way, and often the easiest way, is to have a 
sticky session: a session that’s tied to one node (this is also called session affinity). A sticky session allows you to
ensure that as long as you keep read-your-writes consistency on a node, you’ll get it for sessions too. The downside is 
that sticky sessions reduce the ability of the load balancer to do its job.

Maintaining session consistency with sticky sessions and master-slave replication can be awkward if you want to read from
the slaves to improve read performance but still need to write to the master. One way of handling this is for writes to 
be sent to the slave, who then takes responsibility for forwarding them to the master while maintaining session consistency
for its client. Another approach is to switch the session to the master temporarily when doing a write, just long enough
that reads are done from the master until the slaves have caught up with the update.

### Relaxing Consistency
Consistency is a Good Thing—but, sadly, sometimes we have to sacrifice it. It is always possible to design a system to 
avoid inconsistencies, but often impossible to do so without making unbearable sacrifices in other characteristics of the 
system. As a result, we often have to tradeoff consistency for something else. While some architects see this as a disaster, 
we see it as part of the inevitable tradeoffs involved in system design. Furthermore, different domains have different 
tolerances for inconsistency, and we need to take this tolerance into account as we make our decisions.

Trading off consistency is a familiar concept even in single-server relational database systems. Here, our principal tool
to enforce consistency is the transaction, and transactions can provide strong consistency guarantees. However, transaction
systems usually come with the ability to relax isolation levels, allowing queries to read data that hasn’t been committed
yet, and in practice we see most applications relax consistency down from the highest isolation level (serialized) in order
to get effective performance. We most commonly see people using the read-committed transaction level, which eliminates 
some read-write conflicts but allows others.




