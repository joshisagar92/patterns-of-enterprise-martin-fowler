### Relationships
Aggregates are useful in that they put together data that is commonly accessed together. But there are still lots of cases
where data that’s related is accessed differently. Consider the relationship between a customer and all of his orders. Some
applications will want to access the order history whenever they access the customer; this fits in well with combining the
customer with his order history into a single aggregate. Other applications, however, want to process orders individually
and thus model orders as independent aggregates.

That way, if you need data from the customer record, you read the order, ferret out the customer ID, and make another 
call to the database to read the customer data. This will work, and will be just fine in many scenarios—but the database
will be ignorant of the relationship in the data. This can be important because there are times when it’s useful for the
database to know about these links.

As a result, many databases—even key-value stores—provide ways to make these relationships visible to the database. Document
stores make the content of the aggregate available to the database to form indexes and queries. Riak, a key-value store,
allows you to put link information in metadata, supporting partial retrieval and link-walking capability.

If you update multiple aggregates at once, you have to deal yourself with a failure partway through. Relational databases
help you with this by allowing you to modify multiple records in a single transaction, providing ACID guarantees while
altering many rows.

This may imply that if you have data based on lots of relationships, you should prefer a relational database over a NoSQL
store. While that’s true for aggregate-oriented databases, it’s worth remembering that relational databases aren’t all 
that stellar with complex relationships either.


### Graph Databases
In this context, a graph isn’t a bar chart or histogram; instead, we refer to a graph data structure of nodes connected by edges.

we have a web of information whose nodes are very small (nothing more than a name) but there is a rich 
structure of interconnections between them. With this structure, we can ask questions such as “find the books in the Databases
category that are written by someone whom a friend of mine likes.”

Once you have built up a graph of nodes and edges, a graph database allows you to query that network with query operations
designed with this kind of graph in mind. This is where the important differences between graph and relational databases
come in. Although relational databases can implement relationships using foreign keys, the joins required to navigate around
can get quite expensive—which means performance is often poor for highly connected data models. Graph databases make traversal
along the relationships very cheap. A large part of this is because graph databases shift most of the work of navigating
relationships from query time to insert time. This naturally pays off for situations where querying performance is more 
important than insert speed.

This data model difference has consequences in other aspects, too; you’ll find such databases are more likely to run on a
single server rather than distributed across clusters. ACID transactions need to cover multiple nodes and edges to maintain
consistency. The only thing they have in common with aggregate-oriented databases is their rejection of the relational 
model and an upsurge in attention they received around the same time as the rest of the NoSQL field.


### Schemaless Databases
A common theme across all the forms of NoSQL databases is that they are schemaless. When you want to store data in a 
relational database, you first have to define a schema—a defined structure for the database which says what tables exist,
which columns exist, and what data types each column can hold. Before you store some data, you have to have the schema 
defined for it.

Advocates of schemalessness rejoice in this freedom and flexibility. With a schema, you have to figure out in advance what
you need to store, but that can be hard to do. Without a schema binding you, you can easily store whatever you need. 
This allows you to easily change your data storage as you learn more about your project. You can easily add new things as
you discover them. Furthermore, if you find you don’t need some things anymore, you can just stop storing them, without
worrying about losing old data as you would if you delete columns in a relational schema.

As well as handling changes, a schemaless store also makes it easier to deal with nonuniform data: data where each record
has a different set of fields. A schema puts all rows of a table into a straightjacket, which becomes awkward if you have
different kinds of data in different rows. You either end up with lots of columns that are usually null

Schemalessness is appealing, and it certainly avoids many problems that exist with fixed-schema databases, but it brings
some problems of its own.
The vital, if sometimes inconvenient, fact is that whenever we write a program that accesses data, that program almost always
relies on some form of implicit schema. Unless it just says something like

So, however schemaless our database is, there is usually an implicit schema present. This implicit schema is a set of 
assumptions about the data’s structure in the code that manipulates the data.

Having the implicit schema in the application code results in some problems. It means that in order to understand what 
data is present you have to dig into the application code. If that code is well structured you should be able to find a 
clear place from which to deduce the schema. But there are no guarantees; it all depends on how clear the application code
is. Furthermore, the database remains ignorant of the schema—it can’t use the schema to help it decide how to store and
retrieve data efficiently. It can’t apply its own validations upon that data to ensure that different applications don’t
manipulate data in an inconsistent way.

Essentially, a schemaless database shifts the schema into the application code that accesses it. This becomes problematic
if multiple applications, developed by different people, access the same database. These problems can be reduced with a 
couple of approaches. One is to encapsulate all database interaction within a single application and integrate it with other
applications using web services. This fits in well with many people’s current preference for using web services for integration.
Another approach is to clearly delineate different areas of an aggregate for access by different applications. 


### Materialized Views
When we talked about aggregate-oriented data models, we stressed their advantages. If you want to access orders, it’s useful
to have all the data for an order contained in a single aggregate that can be stored and accessed as a unit. But
aggregate-orientation has a corresponding disadvantage: What happens if a product manager wants to know how much a particular
item has sold over the last couple of weeks? Now the aggregate-orientation works against you, forcing you to potentially
read every order in the database to answer the question. You can reduce this burden by building an index on the product,
but you’re still working against the aggregate structure.

Views provide a mechanism to hide from the client whether data is derived data or base data—but can’t avoid the fact that
some views are expensive to compute. To cope with this, materialized views were invented, which are views that are computed
in advance and cached on disk. Materialized views are effective for data that is read heavily but can stand being somewhat
stale.

Although NoSQL databases don’t have views, they may have precomputed and cached queries, and they reuse the term “materialized view”
to describe them. It’s also much more of a central aspect for aggregate-oriented databases than it is for relational systems, 
since most applications will have to deal with some queries that don’t fit well with the aggregate structure.

There are two rough strategies to building a materialized view. The first is the eager approach where you update the 
materialized view at the same time you update the base data for it. In this case, adding an order would also update the 
purchase history aggregates for each product. This approach is good when you have more frequent reads of the materialized
view than you have writes and you want the materialized views to be as fresh as possible.

If you don’t want to pay that overhead on each update, you can run batch jobs to update the materialized views at regular
intervals. You’ll need to understand your business requirements to assess how stale your materialized views can be.

You can build materialized views outside of the database by reading the data, computing the view, and saving it back to 
the database. More often databases will support building materialized views themselves. In this case, you provide the 
computation that needs to be done, and the database executes the computation when needed according to some parameters that
you configure. This is particularly handy for eager updates of views with incremental map-reduce

### Modeling for Data Access
As mentioned earlier, when modeling data aggregates we need to consider how the data is going to be read as well as what
are the side effects on data related to those aggregates.



